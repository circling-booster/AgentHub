# AgentHub Default Configuration

server:
  host: localhost
  port: 8000

llm:
  default_model: "openai/gpt-4o-mini"
  timeout: 120

storage:
  data_dir: "./data"
  database: "agenthub.db"

health_check:
  interval_seconds: 30
  timeout_seconds: 5

mcp:
  max_active_tools: 100  # Step 11: increased from 30 to support defer loading
  defer_loading_threshold: 30  # Step 11: trigger defer loading above this count
  cache_ttl_seconds: 300
  max_retries: 2
  retry_backoff_seconds: 1.0

observability:
  log_llm_requests: true
  max_log_chars: 500
  log_format: "text"

gateway:
  rate_limit_rps: 5.0
  burst_size: 10
  circuit_failure_threshold: 5
  circuit_recovery_timeout: 60.0
  fallback_enabled: true  # "text" or "json"
