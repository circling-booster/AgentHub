# Phase 4 Part E: Production Hardening

> **ìƒíƒœ:** ğŸ“‹ ì´ˆì•ˆ (Idea Stage)
> **ì„ í–‰ ì¡°ê±´:** Phase 4 Part A-D Complete
> **ëª©í‘œ:** í”„ë¡œë•ì…˜ ì•ˆì •ì„± í™•ë³´ ë° í™•ì¥ì„± ê¸°ë°˜ êµ¬ì¶•
> **ì˜ˆìƒ ê¸°ê°„:** 2ì£¼

---

## ê°œìš”

Phase 4 Part EëŠ” **í”„ë¡œë•ì…˜ í™˜ê²½ ì¤€ë¹„**ë¥¼ ìœ„í•œ ì•ˆì •ì„± ë° í™•ì¥ì„± ê°œì„  ë‹¨ê³„ì…ë‹ˆë‹¤. MCP Gateway íŒ¨í„´, ë¹„ìš© ì¶”ì , ì‹œë§¨í‹± ë„êµ¬ ë¼ìš°íŒ…, Chaos Engineering í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œì˜ ì•ˆì •ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.

**í•µì‹¬ ì„¤ê³„ ì›ì¹™:**
- **Protocol Standards Compliance**: MCP/A2A í‘œì¤€ ì¤€ìˆ˜ (ë…ì í™•ì¥ ê¸ˆì§€)
- **Graceful Degradation**: ì¥ì•  ì‹œ ë¶€ë¶„ ì„œë¹„ìŠ¤ ì œê³µ (Circuit Breaker)
- **Cost Awareness**: LLM ë¹„ìš© ì¶”ì  ë° ì˜ˆì‚° ì§‘í–‰
- **Semantic Intelligence**: ì„ë² ë”© ê¸°ë°˜ ë„êµ¬ ì„ íƒ (Context Overflow ë°©ì§€)

---

## Step ë²ˆí˜¸ ë§¤í•‘

| Step | Title | ì„¤ëª… |
|:----:|-------|------|
| **12** | MCP Gateway Pattern | Circuit Breaker + Rate Limiting + Fallback |
| **13** | Cost Tracking & Budgeting | LiteLLM CustomLogger ê¸°ë°˜ ë¹„ìš© ì¶”ì  |
| **14** | Semantic Tool Routing | Embedding ê¸°ë°˜ ë„êµ¬ ì¶”ì²œ (top-k ì„ íƒ) |
| **15** | Chaos Engineering Tests | MCP ì„œë²„ ì¥ì• , LLM Rate Limit ì‹œë‚˜ë¦¬ì˜¤ |
| **16** | Plugin System (Mock) | ë…ì í™•ì¥ ê²©ë¦¬ ì¸í„°í˜ì´ìŠ¤ (ì‹¤ì œ êµ¬í˜„ Phase 5) |

---

## Step 12: MCP Gateway Pattern

### ëª©í‘œ
MCP ì„œë²„ ì¥ì• ê°€ ì „ì²´ ì‹œìŠ¤í…œìœ¼ë¡œ ì „íŒŒë˜ì§€ ì•Šë„ë¡ Gateway ë ˆì´ì–´ êµ¬ì¶•

### êµ¬í˜„ ê°œìš”

```python
# src/adapters/outbound/mcp/gateway.py
class McpGateway:
    """
    MCP ì„œë²„ ì•ë‹¨ Gateway (Circuit Breaker + Rate Limiting + Fallback)

    Features:
    - Circuit Breaker: ì„œë²„ ì¥ì•  ì‹œ ìë™ ì°¨ë‹¨ (Open â†’ Half-Open â†’ Closed)
    - Rate Limiting: ë„êµ¬ í˜¸ì¶œ ë¹ˆë„ ì œí•œ (Token Bucket ì•Œê³ ë¦¬ì¦˜)
    - Request Pooling: ë™ì¼ ìš”ì²­ ì¤‘ë³µ ë°©ì§€ (LRU Cache)
    - Fallback: ë°±ì—… ì„œë²„ ìë™ ì „í™˜
    """

    def __init__(self):
        self._circuit_breakers: dict[str, CircuitBreaker] = {}
        self._rate_limiters: dict[str, TokenBucketRateLimiter] = {}
        self._request_cache: LRUCache = LRUCache(maxsize=1000, ttl=300)
        self._fallback_map: dict[str, str] = {}  # primary_id -> fallback_id

    async def call_tool(self, endpoint_id: str, tool_name: str, args: dict) -> Any:
        # 1. Circuit Breaker í™•ì¸
        if self._circuit_breakers[endpoint_id].is_open():
            raise CircuitOpenError(f"Circuit open for {endpoint_id}")

        # 2. Rate Limiting
        if not await self._rate_limiters[endpoint_id].allow():
            raise RateLimitExceededError(f"Too many requests to {endpoint_id}")

        # 3. Request Pooling (ìºì‹œ í™•ì¸)
        cache_key = self._make_cache_key(endpoint_id, tool_name, args)
        if cached := self._request_cache.get(cache_key):
            return cached

        # 4. ì‹¤ì œ í˜¸ì¶œ
        try:
            result = await self._do_call(endpoint_id, tool_name, args)
            self._circuit_breakers[endpoint_id].record_success()
            self._request_cache.set(cache_key, result)
            return result
        except Exception as e:
            self._circuit_breakers[endpoint_id].record_failure()

            # 5. Fallback ì‹œë„
            if fallback_id := self._fallback_map.get(endpoint_id):
                logger.warning(f"Primary {endpoint_id} failed, trying fallback {fallback_id}")
                return await self.call_tool(fallback_id, tool_name, args)
            raise


# Circuit Breaker êµ¬í˜„
class CircuitBreaker:
    def __init__(self, failure_threshold: int = 5, timeout: int = 60):
        self._failure_count = 0
        self._failure_threshold = failure_threshold
        self._timeout = timeout
        self._state = CircuitState.CLOSED
        self._opened_at: datetime | None = None

    def is_open(self) -> bool:
        if self._state == CircuitState.OPEN:
            # Half-Open ì „í™˜ í™•ì¸
            if (datetime.now() - self._opened_at).seconds > self._timeout:
                self._state = CircuitState.HALF_OPEN
                return False
            return True
        return False

    def record_success(self):
        if self._state == CircuitState.HALF_OPEN:
            self._state = CircuitState.CLOSED
        self._failure_count = 0

    def record_failure(self):
        self._failure_count += 1
        if self._failure_count >= self._failure_threshold:
            self._state = CircuitState.OPEN
            self._opened_at = datetime.now()
```

### DynamicToolset í†µí•©

```python
# src/adapters/outbound/adk/dynamic_toolset.py
class DynamicToolset(BaseToolset):
    def __init__(self, cache_ttl_seconds: int = 300):
        super().__init__()
        self._gateway = McpGateway()  # Gateway í†µí•©
        # ...

    async def call_tool(self, tool_name: str, arguments: dict[str, Any]) -> Any:
        # Gatewayë¥¼ í†µí•œ í˜¸ì¶œ (Circuit Breaker + Rate Limiting)
        for endpoint_id in self._mcp_toolsets.keys():
            try:
                return await self._gateway.call_tool(endpoint_id, tool_name, arguments)
            except CircuitOpenError:
                continue  # ë‹¤ìŒ ì„œë²„ ì‹œë„
            except ToolNotFoundError:
                continue

        raise ToolNotFoundError(f"Tool not found in any server: {tool_name}")
```

### í…ŒìŠ¤íŠ¸

```python
# tests/unit/adapters/test_mcp_gateway.py
async def test_circuit_breaker_opens_after_failures():
    gateway = McpGateway()

    # 5ë²ˆ ì—°ì† ì‹¤íŒ¨ â†’ Circuit Open
    for _ in range(5):
        with pytest.raises(Exception):
            await gateway.call_tool("endpoint1", "failing_tool", {})

    # Circuit Open í™•ì¸
    with pytest.raises(CircuitOpenError):
        await gateway.call_tool("endpoint1", "any_tool", {})

async def test_fallback_on_primary_failure():
    gateway = McpGateway()
    gateway.register_fallback("primary", "fallback")

    # Primary ì‹¤íŒ¨ ì‹œ Fallback ì„±ê³µ
    result = await gateway.call_tool("primary", "tool", {})
    assert result == "fallback_result"
```

---

## Step 13: Cost Tracking & Budgeting

### ëª©í‘œ
LLM API í˜¸ì¶œ ë¹„ìš©ì„ ì‹¤ì‹œê°„ ì¶”ì í•˜ê³  ì˜ˆì‚° ì´ˆê³¼ ë°©ì§€

### êµ¬í˜„ ê°œìš”

```python
# src/adapters/outbound/adk/cost_tracker.py
from litellm import success_callback, failure_callback

class CostTracker:
    """
    LiteLLM Callbacks ê¸°ë°˜ ë¹„ìš© ì¶”ì 

    Features:
    - ì‹¤ì‹œê°„ ë¹„ìš© ì§‘ê³„ (ëª¨ë¸ë³„/ì‚¬ìš©ìë³„/ëŒ€í™”ë³„)
    - ì˜ˆì‚° ì´ˆê³¼ ì‹œ ìë™ ì°¨ë‹¨ (BudgetExceededError)
    - ì¼ì¼/ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„±
    - SQLite ì €ì¥ (usage.db)
    """

    def __init__(self, budget_manager: BudgetManager, storage: UsageStorage):
        self._budget = budget_manager
        self._storage = storage

    @success_callback
    async def on_llm_success(self, kwargs, completion_response, start_time, end_time):
        """LLM í˜¸ì¶œ ì„±ê³µ ì‹œ ì½œë°±"""
        # ë¹„ìš© ê³„ì‚°
        usage = completion_response.usage
        cost = usage.get("total_cost", 0.0)

        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        user_id = kwargs.get("metadata", {}).get("user_id", "default")
        conversation_id = kwargs.get("metadata", {}).get("conversation_id")
        model = kwargs.get("model")

        # DB ì €ì¥
        await self._storage.record_usage(
            user_id=user_id,
            conversation_id=conversation_id,
            model=model,
            input_tokens=usage.get("prompt_tokens", 0),
            output_tokens=usage.get("completion_tokens", 0),
            cost=cost,
            latency_ms=int((end_time - start_time) * 1000),
        )

        # ì˜ˆì‚° í™•ì¸ (ì›”ë³„)
        monthly_usage = await self._storage.get_monthly_usage(user_id)
        if monthly_usage > self._budget.get_monthly_limit(user_id):
            raise BudgetExceededError(
                f"User {user_id} exceeded monthly budget: ${monthly_usage:.2f}"
            )

    @failure_callback
    async def on_llm_failure(self, kwargs, exception, start_time, end_time):
        """LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì½œë°±"""
        logger.error(f"LLM call failed: {exception}")
        # ì‹¤íŒ¨ë„ ê¸°ë¡ (ë¹„ìš©ì€ 0)
        await self._storage.record_failure(
            user_id=kwargs.get("metadata", {}).get("user_id", "default"),
            model=kwargs.get("model"),
            error=str(exception),
        )


# ì˜ˆì‚° ê´€ë¦¬ì
class BudgetManager:
    """ì‚¬ìš©ìë³„ ì˜ˆì‚° ê´€ë¦¬"""

    def __init__(self):
        self._limits = {
            "default": 100.0,  # $100/month
        }

    def get_monthly_limit(self, user_id: str) -> float:
        return self._limits.get(user_id, self._limits["default"])

    def set_limit(self, user_id: str, limit: float):
        self._limits[user_id] = limit
```

### ADK Orchestrator í†µí•©

```python
# src/adapters/outbound/adk/orchestrator_adapter.py
class AdkOrchestratorAdapter(OrchestratorPort):
    async def initialize(self) -> None:
        # CostTracker ì´ˆê¸°í™” ë° LiteLLM ì½œë°± ë“±ë¡
        self._cost_tracker = CostTracker(
            budget_manager=BudgetManager(),
            storage=SqliteUsageStorage("usage.db"),
        )

        import litellm
        litellm.success_callback = [self._cost_tracker.on_llm_success]
        litellm.failure_callback = [self._cost_tracker.on_llm_failure]

        # Agent ìƒì„±
        self._agent = LlmAgent(...)
```

### í…ŒìŠ¤íŠ¸

```python
# tests/integration/adapters/test_cost_tracker.py
async def test_budget_exceeded_error():
    tracker = CostTracker(
        budget_manager=BudgetManager(),
        storage=FakeUsageStorage(),
    )

    # ì˜ˆì‚° ì„¤ì •: $10
    tracker._budget.set_limit("user1", 10.0)

    # $11 ì†Œë¹„ ì‹œë„
    with pytest.raises(BudgetExceededError):
        await tracker.on_llm_success(
            kwargs={"metadata": {"user_id": "user1"}},
            completion_response={"usage": {"total_cost": 11.0}},
            start_time=0,
            end_time=1,
        )
```

---

## Step 14: Semantic Tool Routing

### ëª©í‘œ
ë„êµ¬ ê°œìˆ˜ ì¦ê°€ ì‹œ Context Overflow ë°©ì§€ (Embedding ê¸°ë°˜ top-k ì„ íƒ)

### êµ¬í˜„ ê°œìš”

```python
# src/domain/services/tool_router.py
class SemanticToolRouter:
    """
    Embedding ê¸°ë°˜ ì‹œë§¨í‹± ë„êµ¬ ë¼ìš°íŒ…

    Phase 4D Step 11 (Defer Loading) í™•ì¥:
    - Defer Loading: ë„êµ¬ ë©”íƒ€ë°ì´í„°ë§Œ ë¡œë“œ (30ê°œ ì´ˆê³¼ ì‹œ)
    - Semantic Routing: ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë„êµ¬ top-k ì„ íƒ
    """

    def __init__(self, embedding_model: str = "text-embedding-3-small"):
        self._embedder = OpenAIEmbeddings(model=embedding_model)
        self._tool_index: dict[str, np.ndarray] = {}  # tool_name -> embedding
        self._tool_metadata: dict[str, ToolMetadata] = {}

    async def index_tool(self, tool: Tool) -> None:
        """ë„êµ¬ ì„¤ëª… ì„ë² ë”© ìƒì„± ë° ì¸ë±ì‹±"""
        description = f"{tool.name}: {tool.description}"
        embedding = await self._embedder.embed(description)

        self._tool_index[tool.name] = embedding
        self._tool_metadata[tool.name] = ToolMetadata(
            name=tool.name,
            description=tool.description,
            endpoint_id=tool.endpoint_id,
        )

    async def route(self, user_query: str, top_k: int = 5) -> list[str]:
        """ì‚¬ìš©ì ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë„êµ¬ top-k ë°˜í™˜"""
        if not self._tool_index:
            return []

        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = await self._embedder.embed(user_query)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = {
            name: self._cosine_similarity(query_embedding, tool_emb)
            for name, tool_emb in self._tool_index.items()
        }

        # Top-k ì„ íƒ
        sorted_tools = sorted(similarities.items(), key=lambda x: x[1], reverse=True)
        return [name for name, _ in sorted_tools[:top_k]]

    @staticmethod
    def _cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
```

### OrchestratorService í†µí•©

```python
# src/domain/services/orchestrator.py
class OrchestratorService:
    def __init__(
        self,
        conversation_service: ConversationService,
        tool_router: SemanticToolRouter | None = None,
    ):
        self._conversation = conversation_service
        self._router = tool_router

    async def chat(self, conversation_id: str, message: str) -> AsyncIterator[StreamChunk]:
        # Semantic Routing í™œì„±í™” ì‹œ
        if self._router:
            selected_tools = await self._router.route(message, top_k=5)
            # DynamicToolsetì— ì„ íƒëœ ë„êµ¬ë§Œ í™œì„±í™”
            # (ì‹¤ì œ êµ¬í˜„ì€ DynamicToolset í™•ì¥ í•„ìš”)

        # ëŒ€í™” ì²˜ë¦¬
        async for chunk in self._conversation.process_message(...):
            yield chunk
```

### í…ŒìŠ¤íŠ¸

```python
# tests/unit/domain/services/test_tool_router.py
async def test_semantic_routing_selects_relevant_tools():
    router = SemanticToolRouter()

    # ë„êµ¬ ì¸ë±ì‹±
    await router.index_tool(Tool(name="web_search", description="Search the web for information"))
    await router.index_tool(Tool(name="calculator", description="Perform mathematical calculations"))
    await router.index_tool(Tool(name="slack_send", description="Send message to Slack channel"))

    # ì¿¼ë¦¬: "What is 2+2?"
    selected = await router.route("What is 2+2?", top_k=2)

    # calculatorê°€ ìµœìƒìœ„ì—¬ì•¼ í•¨
    assert selected[0] == "calculator"
```

---

## Step 15: Chaos Engineering Tests

### ëª©í‘œ
í”„ë¡œë•ì…˜ ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ (MCP ì„œë²„ ë‹¤ìš´, LLM Rate Limit ë“±)

### êµ¬í˜„ ê°œìš”

```python
# tests/chaos/scenarios.py
import pytest
import asyncio
from httpx import AsyncClient

class ChaosScenarios:
    """í”„ë¡œë•ì…˜ ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤"""

    @pytest.mark.chaos
    async def test_mcp_server_sudden_death(self, client: AsyncClient, mcp_server):
        """ì‹œë‚˜ë¦¬ì˜¤ 1: MCP ì„œë²„ ê°‘ì‘ìŠ¤ëŸ° ì¢…ë£Œ"""
        # 1. ì •ìƒ ìƒíƒœ í™•ì¸
        response = await client.post("/api/chat/stream", json={
            "conversation_id": "test",
            "message": "Use the search tool",
        })
        assert response.status_code == 200

        # 2. MCP ì„œë²„ ê°•ì œ ì¢…ë£Œ (SIGKILL)
        await mcp_server.kill()

        # 3. ì‹œìŠ¤í…œ ë³µêµ¬ í™•ì¸ (Circuit Breaker ì‘ë™ ëŒ€ê¸°)
        await asyncio.sleep(10)

        # 4. Health ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
        response = await client.get("/health")
        assert response.status_code == 200
        data = response.json()

        # 5. Degraded ìƒíƒœ í™•ì¸ (ì™„ì „ ì‹¤íŒ¨ëŠ” ì•„ë‹˜)
        assert data["status"] == "degraded"
        assert "mcp_server_1" in data["unavailable_services"]

        # 6. ì±„íŒ…ì€ ì—¬ì „íˆ ê°€ëŠ¥ (ë„êµ¬ ì—†ì´)
        response = await client.post("/api/chat/stream", json={
            "conversation_id": "test",
            "message": "Hello",
        })
        assert response.status_code == 200

    @pytest.mark.chaos
    async def test_llm_rate_limit_cascade(self, client: AsyncClient):
        """ì‹œë‚˜ë¦¬ì˜¤ 2: LLM Rate Limit â†’ ëŒ€í™” ì‹¤íŒ¨ í­í¬ìˆ˜"""
        # 1. 100ê°œ ë™ì‹œ ìš”ì²­ â†’ Rate Limit ìœ ë°œ
        tasks = [
            client.post("/api/chat/stream", json={
                "conversation_id": f"conv_{i}",
                "message": "Hello",
            })
            for i in range(100)
        ]

        responses = await asyncio.gather(*tasks, return_exceptions=True)

        # 2. ì¼ë¶€ëŠ” ì„±ê³µ, ì¼ë¶€ëŠ” 429 ì—ëŸ¬
        success = [r for r in responses if not isinstance(r, Exception) and r.status_code == 200]
        failures = [r for r in responses if isinstance(r, Exception) or r.status_code == 429]

        # 3. ê²€ì¦
        assert len(success) > 0, "At least some requests should succeed"
        assert len(failures) > 0, "Rate limiting should kick in"

        # 4. ì‹œìŠ¤í…œ ë³µêµ¬ í™•ì¸ (10ì´ˆ í›„)
        await asyncio.sleep(10)
        response = await client.post("/api/chat/stream", json={
            "conversation_id": "recovery_test",
            "message": "Hello",
        })
        assert response.status_code == 200, "System should recover after cooldown"

    @pytest.mark.chaos
    async def test_concurrent_tool_calls_race_condition(self, client: AsyncClient):
        """ì‹œë‚˜ë¦¬ì˜¤ 3: ë™ì‹œ ë„êµ¬ í˜¸ì¶œ ê²½ìŸ ì¡°ê±´"""
        # ë™ì¼ ë„êµ¬ë¥¼ ë™ì‹œ í˜¸ì¶œ (Request Pooling í…ŒìŠ¤íŠ¸)
        tasks = [
            client.post("/api/tools/call", json={
                "tool_name": "expensive_tool",
                "arguments": {"query": "same_query"},
            })
            for _ in range(50)
        ]

        responses = await asyncio.gather(*tasks)

        # ëª¨ë“  ì‘ë‹µì´ ë™ì¼í•´ì•¼ í•¨ (ìºì‹±)
        results = [r.json()["result"] for r in responses]
        assert len(set(results)) == 1, "All responses should be cached"
```

### CI í†µí•©

```yaml
# .github/workflows/chaos.yml
name: Chaos Engineering Tests

on:
  schedule:
    - cron: '0 2 * * *'  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
  workflow_dispatch:

jobs:
  chaos:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -e ".[dev]"

      - name: Run Chaos Tests
        run: pytest tests/chaos/ -v --tb=short -m chaos
```

---

## Step 16: Plugin System (Mock Implementation)

### ëª©í‘œ
ë…ìì  í™•ì¥ì„ ê²©ë¦¬í•˜ì—¬ MCP/A2A í‘œì¤€ ì¤€ìˆ˜ ë³´ì¥

### ì„¤ê³„ ì›ì¹™

**Protocol Standards Compliance (CLAUDE.md Principle #7):**
- MCP í•µì‹¬ ê¸°ëŠ¥: í‘œì¤€ ì¤€ìˆ˜
- A2A í”„ë¡œí† ì½œ: 0.3 ìŠ¤í™ ê¸°ë°˜
- ë…ì í™•ì¥: Plugin Systemìœ¼ë¡œ ê²©ë¦¬

### ì¸í„°í˜ì´ìŠ¤ ì •ì˜ (Mock)

```python
# src/domain/ports/plugin_port.py
from abc import ABC, abstractmethod
from typing import Any

class PluginInterface(ABC):
    """
    Plugin System ì¸í„°í˜ì´ìŠ¤ (Phase 4E Mock)

    ì‹¤ì œ êµ¬í˜„ì€ Phase 5ì—ì„œ ì§„í–‰.
    ë…ìì  í™•ì¥(LangChain, AutoGen ë“±)ì„ MCP/A2Aì™€ ê²©ë¦¬í•˜ì—¬
    í”„ë¡œí† ì½œ ì—…ê·¸ë ˆì´ë“œ ì‹œ ì˜í–¥ ìµœì†Œí™”.
    """

    @abstractmethod
    async def initialize(self, config: dict[str, Any]) -> None:
        """í”ŒëŸ¬ê·¸ì¸ ì´ˆê¸°í™”"""
        pass

    @abstractmethod
    async def get_capabilities(self) -> list[str]:
        """ì œê³µ ê¸°ëŠ¥ ëª©ë¡ (ì˜ˆ: ["langchain_agent", "retrieval_qa"])"""
        pass

    @abstractmethod
    async def execute(self, capability: str, request: dict[str, Any]) -> dict[str, Any]:
        """ê¸°ëŠ¥ ì‹¤í–‰"""
        pass

    @abstractmethod
    async def shutdown(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        pass


# ì˜ˆì‹œ: LangChain Plugin (Mock)
class LangChainPlugin(PluginInterface):
    """LangChain ì—ì´ì „íŠ¸ë¥¼ AgentHubì— í†µí•© (Phase 5 êµ¬í˜„ ì˜ˆì •)"""

    async def initialize(self, config: dict[str, Any]) -> None:
        # from langchain.agents import initialize_agent
        # self._agent = initialize_agent(...)
        pass

    async def get_capabilities(self) -> list[str]:
        return ["langchain_agent", "retrieval_qa", "react_agent"]

    async def execute(self, capability: str, request: dict[str, Any]) -> dict[str, Any]:
        # result = await self._agent.arun(request["query"])
        # return {"result": result}
        return {"result": "mock_result"}

    async def shutdown(self) -> None:
        pass
```

### Plugin ì•„ì´ë””ì–´ (Phase 5 ê¸°íš ì°¸ê³ ìš©)

> **ì£¼ì˜:** ì•„ë˜ ì•„ì´ë””ì–´ëŠ” ì´ˆì•ˆ ë‹¨ê³„ì´ë©°, Phase 5 ê³„íš ìˆ˜ë¦½ ì‹œ ì°¸ê³ ìš©ì…ë‹ˆë‹¤.
> Phase 4Eì—ì„œëŠ” ì¸í„°í˜ì´ìŠ¤ ì •ì˜ë§Œ ì§„í–‰í•˜ê³ , ì‹¤ì œ êµ¬í˜„ì€ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

#### 1. Agent Framework Plugins â­ (ìµœìš°ì„  í›„ë³´)

**LangChain Plugin:**
```python
# ë¬¸ì„œ ê²€ìƒ‰, ReAct Agent, SQL Agent ë“± ì œê³µ
capabilities = [
    "langchain_retrieval_qa",    # ë²¡í„° DB ê¸°ë°˜ ë¬¸ì„œ QA
    "langchain_react_agent",     # ì¶”ë¡ +í–‰ë™ ë°˜ë³µ ì—ì´ì „íŠ¸
    "langchain_sql_agent",       # ìì—°ì–´ â†’ SQL ì¿¼ë¦¬
]

# ì‚¬ìš© ì˜ˆì‹œ:
# "ë‚´ ë¬¸ì„œ í´ë”ì—ì„œ 'AI ìœ¤ë¦¬' ê´€ë ¨ ë‚´ìš© ì°¾ì•„ì¤˜"
# â†’ LangChain RetrievalQA ì‹¤í–‰ â†’ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜
```

**AutoGen Plugin:**
```python
# Microsoft AutoGenì˜ Multi-Agent í˜‘ì—…
capabilities = [
    "autogen_group_chat",        # ì—¬ëŸ¬ ì—ì´ì „íŠ¸ íšŒì˜
    "autogen_code_executor",     # ìƒŒë“œë°•ìŠ¤ ì½”ë“œ ì‹¤í–‰
]

# ì‚¬ìš© ì˜ˆì‹œ:
# "ì½”ë“œ ë¦¬ë·°í•´ì¤˜" â†’ Coder + Reviewer ì—ì´ì „íŠ¸ í˜‘ì—…
```

**CrewAI Plugin:**
```python
# ì—­í•  ê¸°ë°˜ ì—ì´ì „íŠ¸ íŒ€
capabilities = [
    "crewai_research_crew",      # ë¦¬ì„œì¹˜ â†’ ë¶„ì„ â†’ ë³´ê³ ì„œ íŒŒì´í”„ë¼ì¸
]
```

#### 2. Custom Protocol Adapters

**GraphQL Adapter Plugin:**
```python
# GraphQL APIë¥¼ MCP ë„êµ¬ì²˜ëŸ¼ ì‚¬ìš©
# ì˜ˆì‹œ: GitHub GraphQL API
capabilities = [
    "github_get_user",
    "github_list_repos",
    "github_create_issue",
]
```

**gRPC Service Plugin:**
```python
# ë‚´ë¶€ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ë¥¼ A2A Agentì²˜ëŸ¼ ë…¸ì¶œ
# ì˜ˆì‹œ: íšŒì‚¬ ë‚´ë¶€ gRPC ì„œë¹„ìŠ¤ í†µí•©
```

**Legacy REST API Wrapper:**
```python
# ë³µì¡í•œ ì¸ì¦/ì„¸ì…˜ ê´€ë¦¬ë¥¼ ë˜í•‘
# ì˜ˆì‹œ: OAuth 2.0 ê¸°ë°˜ ë‚´ë¶€ API
```

#### 3. Domain-Specific Tools â­

**Code Analysis Plugin:**
```python
capabilities = [
    "analyze_complexity",           # ìˆœí™˜ ë³µì¡ë„ ë¶„ì„
    "detect_code_smells",           # ì½”ë“œ ìŠ¤ë©œ íƒì§€
    "generate_dependency_graph",    # ì˜ì¡´ì„± ê·¸ë˜í”„
    "find_security_vulnerabilities" # Bandit ê¸°ë°˜ ë³´ì•ˆ ê²€ì‚¬
]
```

**Data Science Plugin:**
```python
capabilities = [
    "visualize_dataframe",          # Pandas + Matplotlib ì‹œê°í™”
    "train_ml_model",               # Scikit-learn ëª¨ë¸ í•™ìŠµ
    "statistical_analysis",         # í†µê³„ ë¶„ì„
]

# ì‚¬ìš© ì˜ˆì‹œ:
# "CSV íŒŒì¼ ì‹œê°í™”í•´ì¤˜" â†’ Base64 ì¸ì½”ë”© ì´ë¯¸ì§€ ë°˜í™˜
```

**Document Processing Plugin:**
```python
capabilities = [
    "extract_pdf_text",             # PyPDF2 ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    "ocr_image",                    # Tesseract OCR
    "summarize_document",           # ë¬¸ì„œ ìš”ì•½
    "translate_document",           # ë‹¤êµ­ì–´ ë²ˆì—­
]
```

#### 4. UI Extension Plugins ğŸ¨

```typescript
// Extension UIì— ì»¤ìŠ¤í…€ ì»´í¬ë„ŒíŠ¸ ì¶”ê°€
interface UiPlugin {
  renderPanel(): React.Component;           // ì»¤ìŠ¤í…€ íŒ¨ë„
  renderMessage(message): React.Component;  // ë©”ì‹œì§€ ë Œë”ëŸ¬ í™•ì¥
  getToolbarButtons(): ToolbarButton[];     // íˆ´ë°” ë²„íŠ¼ ì¶”ê°€
}

// ì˜ˆì‹œ 1: Mermaid Diagram Renderer
class MermaidPlugin {
  renderMessage(message) {
    if (message.type === "mermaid_diagram") {
      return <MermaidViewer code={message.content} />;
    }
  }
}

// ì˜ˆì‹œ 2: Interactive Data Table
class DataTablePlugin {
  renderMessage(message) {
    if (message.type === "dataframe") {
      return <DataGrid data={message.data} />;
    }
  }

  getToolbarButtons() {
    return [{ icon: "ğŸ“Š", label: "Export CSV", onClick: ... }];
  }
}
```

#### 5. Security & Compliance Plugins ğŸ”’

**PII Redaction Plugin:**
```python
# ê°œì¸ì •ë³´ ìë™ ë§ˆìŠ¤í‚¹ (GDPR/HIPAA ì¤€ìˆ˜)
capabilities = [
    "redact_pii",                   # ì´ë©”ì¼, ì „í™”ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
    "detect_sensitive_data",        # ë¯¼ê° ë°ì´í„° íƒì§€
]

# ì‚¬ìš© ì˜ˆì‹œ:
# ì…ë ¥: "ë‚´ ì´ë©”ì¼ì€ user@example.comì…ë‹ˆë‹¤"
# ì¶œë ¥: "ë‚´ ì´ë©”ì¼ì€ ***@***.***ì…ë‹ˆë‹¤"
```

**Audit Log Plugin:**
```python
# ê°ì‚¬ ë¡œê·¸ ìë™ ìƒì„±
capabilities = [
    "log_action",                   # ëª¨ë“  ë„êµ¬ í˜¸ì¶œ ê¸°ë¡
    "generate_compliance_report",   # ê·œì • ì¤€ìˆ˜ ë¦¬í¬íŠ¸
]
```

#### Plugin Manager Architecture

```python
# src/domain/services/plugin_manager.py
class PluginManager:
    """
    Plugin ìƒëª…ì£¼ê¸° ê´€ë¦¬

    ê¸°ëŠ¥:
    - ë™ì  ë¡œë”©/ì–¸ë¡œë”© (Hot Reload)
    - ì˜ì¡´ì„± í•´ê²°
    - ê²©ë¦¬ ì‹¤í–‰ (ì‹¤íŒ¨ ì‹œ Core ì˜í–¥ ì—†ìŒ)
    - Timeout ì„¤ì • (Runaway Plugin ë°©ì§€)
    """

    async def register(self, plugin: PluginInterface, config: dict):
        """Plugin ë“±ë¡ (ì‹¤íŒ¨í•´ë„ Core ê³„ì† ë™ì‘)"""
        pass

    async def execute(self, capability: str, request: dict) -> dict:
        """Capability ì‹¤í–‰ (5ë¶„ timeout)"""
        pass
```

#### Plugin ë°°í¬ (Phase 5 ê²€í†  ì‚¬í•­)

```yaml
# plugins/langchain-plugin.yaml
name: langchain-plugin
version: 1.0.0
author: AgentHub Community
description: LangChain integration for AgentHub

entry_point: plugins.langchain_plugin.LangChainPlugin

dependencies:
  - langchain>=0.1.0
  - chromadb>=0.4.0

capabilities:
  - name: langchain_retrieval_qa
    description: Retrieval-based QA over documents
    input_schema:
      query: string
      top_k: integer
```

```bash
# CLIë¡œ Plugin ì„¤ì¹˜ (Phase 5 ê²€í† )
agenthub plugin install langchain-plugin

# ë˜ëŠ” Extension UIì—ì„œ Marketplace í†µí•´ ì„¤ì¹˜
```

#### Plugin ìš°ì„ ìˆœìœ„ (Phase 5 ê¸°íš ì°¸ê³ )

| ìš°ì„ ìˆœìœ„ | Plugin ìœ í˜• | ì´ìœ  |
|:-------:|------------|------|
| **1** | Agent Frameworks (LangChain, AutoGen) | ê³ ê¸‰ ê¸°ëŠ¥ ì¦‰ì‹œ ì œê³µ |
| **2** | Domain-Specific (Code, Data Science) | ì‹¤ë¬´ íš¨ìš© ë†’ìŒ |
| **3** | Custom Protocol Adapters | ê¸°ì—… í™˜ê²½ ëŒ€ì‘ |
| **4** | UI Extensions | UX ê°œì„  |
| **5** | Security & Compliance | ì—”í„°í”„ë¼ì´ì¦ˆ í•„ìš” ì‹œ |

### ë¬¸ì„œí™”

```python
# docs/architecture/plugin-system.md (ìƒˆë¡œ ìƒì„± - Phase 5)
"""
# Plugin System Architecture

## ì„¤ê³„ ëª©ì 

MCP/A2A í‘œì¤€ì„ ì¤€ìˆ˜í•˜ë©´ì„œë„ ë…ìì  í™•ì¥ì„ í—ˆìš©í•˜ê¸° ìœ„í•œ ê²©ë¦¬ ë©”ì»¤ë‹ˆì¦˜.

## ì§€ì› í”ŒëŸ¬ê·¸ì¸ ìœ í˜•

1. **Agent Frameworks**: LangChain, AutoGen, CrewAI
2. **Custom Protocols**: ë¹„í‘œì¤€ ì—ì´ì „íŠ¸ í”„ë¡œí† ì½œ
3. **Specialized Tools**: ë„ë©”ì¸ íŠ¹í™” ë„êµ¬ (RAG, ì½”ë“œ ë¶„ì„ ë“±)

## í”ŒëŸ¬ê·¸ì¸ ë“±ë¡

```python
plugin_manager = PluginManager()
await plugin_manager.register(LangChainPlugin(), config={...})
```

## ê²©ë¦¬ ë³´ì¥

- í”ŒëŸ¬ê·¸ì¸ ì‹¤íŒ¨ê°€ Core Systemì— ì˜í–¥ ì—†ìŒ
- MCP/A2A í‘œì¤€ ì—…ê·¸ë ˆì´ë“œ ì‹œ í”ŒëŸ¬ê·¸ì¸ ë…ë¦½ ì—…ë°ì´íŠ¸
"""
```

---

## ë³´ë¥˜ í•­ëª©: Event-Driven Architecture (Job Queue)

### ë³´ë¥˜ ì´ìœ 

**í˜„ì¬ ë‹¨ê³„ì—ì„œ ë¶ˆí•„ìš”:**
- AgentHubëŠ” **ë‹¨ì¼ ì‚¬ìš©ì** ë¡œì»¬ ì•± (Multi-Tenancy ë¯¸ì§€ì›)
- ëŒ€ë¶€ë¶„ ì‘ì—…ì´ **30ì´ˆ ì´ë‚´** ì™„ë£Œ (Offscreen Documentë¡œ ì¶©ë¶„, ìµœëŒ€ 5ë¶„ ì§€ì›)
- Job Queue ë„ì… ì‹œ **ë³µì¡ë„ ë° ì‚¬ìš©ì ì§„ì…ì¥ë²½ ê¸‰ì¦** (ì•„ë˜ ìƒì„¸ ë¶„ì„ ì°¸ì¡°)

**ì¬ê²€í†  ì‹œì :**
- Multi-User Support êµ¬í˜„ ì‹œ (Phase 5+)
- ì¥ì‹œê°„ ì‘ì—… (5ë¶„ ì´ìƒ) ë¹„ìœ¨ì´ 20% ì´ˆê³¼ ì‹œ
- ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìš”êµ¬ì‚¬í•­ ë°œìƒ ì‹œ (ì˜ˆ: ì¼ê´„ ë°ì´í„° ì²˜ë¦¬)
- **í´ë¼ìš°ë“œ ë°°í¬ ê²°ì • ì‹œ** (ì‚¬ìš©ì PC â†’ ì„œë²„ë¡œ ì‹¤í–‰ í™˜ê²½ ë³€ê²½)

### Event-Driven Architecture ê°œìš”

**ì¥ì :**
- âœ… **ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬**: ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ (5ë¶„ ì´ìƒ ê°€ëŠ¥)
- âœ… **í™•ì¥ì„±**: ì›Œì»¤ ìˆ˜í‰ í™•ì¥ìœ¼ë¡œ ì²˜ë¦¬ëŸ‰ ì¦ê°€
- âœ… **íƒ„ë ¥ì„±**: ì‘ì—… ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„, ë°ë“œë ˆí„° í

**ë‹¨ì :**
- âŒ **ë³µì¡ë„ ì¦ê°€**: Message Broker (Redis, RabbitMQ), Worker í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬
- âŒ **ë””ë²„ê¹… ì–´ë ¤ì›€**: ë¹„ë™ê¸° íë¦„ ì¶”ì , ì´ë²¤íŠ¸ ìˆœì„œ ë³´ì¥ ì–´ë ¤ì›€
- âŒ **ì‚¬ìš©ì ë¶€ë‹´ ì¦ê°€**: ë¦¬ì†ŒìŠ¤ ë¹„ìš©, Docker ì˜ì¡´ì„±, ì„¤ì • ë³µì¡ë„ (ì•„ë˜ ìƒì„¸ ë¶„ì„)

---

### âš ï¸ ë¹„ìš© ë° ë³µì¡ë„ ìƒì„¸ ë¶„ì„

#### ğŸ’° ë¹„ìš© ë¶€ë‹´: **ì‚¬ìš©ì(ì´ìš©ì) ë¶€ë‹´**

AgentHubëŠ” **ë¡œì»¬ ì•±**ì´ë¯€ë¡œ:
- ê°œë°œì(AgentHub)ëŠ” **ì†Œí”„íŠ¸ì›¨ì–´ë§Œ ì œê³µ** (ì˜¤í”ˆì†ŒìŠ¤)
- ì‚¬ìš©ìê°€ **ìì‹ ì˜ PCì—ì„œ ì¸í”„ë¼ ì‹¤í–‰**
- Redis, Celery WorkerëŠ” **ì‚¬ìš©ì PC ë¦¬ì†ŒìŠ¤ ì†Œë¹„**

**êµ¬ì²´ì  ë¦¬ì†ŒìŠ¤ ì†Œë¹„:**
```
ì‚¬ìš©ì PCì—ì„œ ì‹¤í–‰ë˜ëŠ” í”„ë¡œì„¸ìŠ¤:
1. AgentHub Server (FastAPI)         : RAM 200MB, CPU 0.5 ì½”ì–´
2. Redis (Message Broker)           : RAM 500MB ~ 2GB
3. Celery Worker (1-2ê°œ)            : RAM 500MB ~ 1GB, CPU 1-2 ì½”ì–´
-------------------------------------------------------------
ì´í•©                                : RAM 1.2GB ~ 3.2GB, CPU 1.5-2.5 ì½”ì–´ ìƒì‹œ ì ìœ 
ë°°í„°ë¦¬ ì†Œëª¨                          : ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ìŠ¤ë¡œ 20-30% ì¦ê°€
```

**ì €ì‚¬ì–‘ ê¸°ê¸° ì˜í–¥:**
- RAM 8GB ë…¸íŠ¸ë¶: **AgentHub ì‹¤í–‰ ì‹œ ë‹¤ë¥¸ ì•± ì‚¬ìš© ì œì•½**
- ê°œë°œì PC (RAM 16GB+): ë¬¸ì œì—†ìŒ
- **ì¼ë°˜ ì‚¬ìš©ì (RAM 8GB ì´í•˜)**: ì‚¬ìš© ë¶ˆê°€ëŠ¥ ìˆ˜ì¤€

#### ğŸ³ Docker í•„ìˆ˜ ì—¬ë¶€: **ê±°ì˜ í•„ìˆ˜** (95%)

**Docker ì—†ì´ ì„¤ì¹˜ ì‹œ (ìˆ˜ë™ ì„¤ì¹˜):**

| OS | ì„¤ì¹˜ ë‚œì´ë„ | ì˜ˆìƒ ì‹œê°„ | ì¼ë°˜ ì‚¬ìš©ì ì„±ê³µë¥  |
|----|:-----------:|:---------:|:----------------:|
| **Windows** | âš ï¸âš ï¸âš ï¸ ë§¤ìš° ì–´ë ¤ì›€ | 1-2ì‹œê°„ | **< 5%** |
| **macOS** | âš ï¸âš ï¸ ì–´ë ¤ì›€ | 30ë¶„ | **< 20%** |
| **Linux** | âš ï¸ ì¤‘ê°„ | 15ë¶„ | 50% |

**Windows ìˆ˜ë™ ì„¤ì¹˜ ê³¼ì • (ë¹„ê°œë°œì ê´€ì ):**
```bash
# 1. WSL 2 ì„¤ì¹˜ (Windows Subsystem for Linux)
wsl --install  # Windows ì¬ì‹œì‘ í•„ìš”

# 2. Ubuntu ì‹¤í–‰ ë° Redis ì„¤ì¹˜
wsl -d Ubuntu
sudo apt update
sudo apt install redis-server

# 3. Redis ì„œë²„ ì‹¤í–‰
redis-server --daemonize yes

# 4. Python ê°€ìƒí™˜ê²½ ë° Celery ì„¤ì¹˜
cd /mnt/c/Users/UserName/AgentHub
python -m venv .venv
source .venv/bin/activate
pip install celery redis

# 5. Celery Worker ì‹¤í–‰
celery -A src.workers worker --loglevel=info

â†’ "WSLì´ ë­”ê°€ìš”?", "ì™œ Linuxë¥¼ ì„¤ì¹˜í•˜ë‚˜ìš”?" í¬ê¸° ğŸ˜¢
```

**Docker ì‚¬ìš© ì‹œ:**
```bash
# 1. Docker Desktop ì„¤ì¹˜ (GUI ì¸ìŠ¤í†¨ëŸ¬)
# https://www.docker.com/products/docker-desktop

# 2. í”„ë¡œì íŠ¸ í´ë”ì—ì„œ ì‹¤í–‰ (í´ë¦­ í•œ ë²ˆ)
docker-compose up -d

â†’ í›¨ì”¬ ê°„ë‹¨í•˜ì§€ë§Œ, Docker ì„¤ì¹˜ ìì²´ê°€ ì§„ì…ì¥ë²½ (4GB ë‹¤ìš´ë¡œë“œ)
```

**Docker ì˜ì¡´ì„± ë¬¸ì œ:**
- Docker Desktop ë¼ì´ì„ ìŠ¤: ê°œì¸/ì†Œê·œëª¨ëŠ” ë¬´ë£Œ, **ëŒ€ê¸°ì—…ì€ ìœ ë£Œ** ($9/ì›”)
- Docker Daemon ìƒì‹œ ì‹¤í–‰: **RAM 2GB ì¶”ê°€ ì†Œëª¨**
- Windows Home ì—ë””ì…˜: Docker Desktop ë¯¸ì§€ì› (WSL 2 ë°±ì—”ë“œ í•„ìš”)

#### ğŸ“‰ ì¼ë°˜ ì‚¬ìš©ì í™•ì¥ì„±: **ë§¤ìš° ë–¨ì–´ì§** âŒ

| ì‚¬ìš©ì ìœ í˜• | Docker ì—†ì´ | Docker ìˆì–´ë„ | í‰ê°€ |
|------------|:----------:|:------------:|:----:|
| **ê°œë°œì** (CLI ìµìˆ™) | âš ï¸ ê°€ëŠ¥ (30ë¶„ ì„¤ì •) | âœ… ì‰¬ì›€ (5ë¶„ ì„¤ì •) | OK |
| **íŒŒì›Œìœ ì €** (ê¸°ìˆ  ì§€ì‹ ìˆìŒ) | âŒ ì–´ë ¤ì›€ (2ì‹œê°„ ì„¤ì •) | âš ï¸ ê°€ëŠ¥ (30ë¶„ ì„¤ì •) | ì§„ì…ì¥ë²½ ë†’ìŒ |
| **ì¼ë°˜ ì‚¬ìš©ì** (ë¹„ê°œë°œì) | âŒ ë¶ˆê°€ëŠ¥ | âŒ ê±°ì˜ ë¶ˆê°€ëŠ¥ | **í™•ì¥ì„± 0%** |

**ì¼ë°˜ ì‚¬ìš©ì ì„¤ì¹˜ ì‹œë‚˜ë¦¬ì˜¤ (ì‹¤íŒ¨ ì˜ˆìƒ):**
```
1. AgentHub ë‹¤ìš´ë¡œë“œ â†’ âœ… ì„±ê³µ
2. "Docker Desktopì„ ì„¤ì¹˜í•˜ì„¸ìš”" â†’ â“ ë­ì§€?
3. Docker ì„¤ì¹˜ ì‹œì‘ (4GB ë‹¤ìš´ë¡œë“œ) â†’ â³ ì™œ ì´ë ‡ê²Œ ì˜¤ë˜ ê±¸ë¦¬ì§€?
4. WSL 2 ì—…ë°ì´íŠ¸ í•„ìš” â†’ ğŸ˜µ ë¬´ìŠ¨ ë§ì¸ì§€ ëª¨ë¥´ê² ìŒ
5. docker-compose up -d ì‹¤í–‰ â†’ ğŸ’» ëª…ë ¹ì¤„? ì–´ë””ì„œ ì¹˜ë‚˜ìš”?
6. "Redis connection refused" ì—ëŸ¬ â†’ ğŸ˜­ í¬ê¸°

â†’ ChatGPT Desktop, Claude Desktopì²˜ëŸ¼ "ì„¤ì¹˜ í›„ í´ë¦­ë§Œ" UX ë¶ˆê°€ëŠ¥
```

**ê²°ë¡ :**
- Event-Driven ë„ì… ì‹œ **ì‚¬ìš©ìì¸µì´ "ê°œë°œì/íŒŒì›Œìœ ì €"ë¡œ ì œí•œë¨**
- ëŒ€ì¤‘í™” (Mass Adoption) **ë¶ˆê°€ëŠ¥**
- AgentHubì˜ ëª©í‘œê°€ "ë¡œì»¬ ê°œë°œ ë„êµ¬"ë¼ë©´ OK
- ëª©í‘œê°€ "ì¼ë°˜ ì‚¬ìš©ìë„ ì“°ëŠ” ì•±"ì´ë¼ë©´ **ì¹˜ëª…ì  ì¥ì• **

---

### êµ¬í˜„ ì˜ˆì‹œ (ì°¸ê³ ìš© - Phase 5)

```python
# src/domain/events/event_bus.py (ë³´ë¥˜)
class DomainEvent:
    event_id: str
    occurred_at: datetime
    user_id: str

class ToolCallStarted(DomainEvent):
    tool_name: str
    arguments: dict

class ToolCallCompleted(DomainEvent):
    tool_name: str
    result: Any
    duration_ms: int

# src/adapters/outbound/queue/celery_adapter.py (ë³´ë¥˜)
from celery import Celery

app = Celery('agenthub', broker='redis://localhost:6379/0')

@app.task
def execute_long_running_tool(tool_name: str, arguments: dict):
    """ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…: ì¥ì‹œê°„ ë„êµ¬ ì‹¤í–‰"""
    result = tool_executor.execute(tool_name, arguments)
    # ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰
    event_bus.publish(ToolCallCompleted(...))
    return result
```

### âœ… í˜„ì¬ ëŒ€ì•ˆ: Offscreen Document (ì¶©ë¶„íˆ íš¨ê³¼ì )

**AgentHubëŠ” Offscreen Documentë¡œ ì¶©ë¶„í•œ ì´ìœ :**
- âœ… Service Worker 30ì´ˆ ì œì•½ íšŒí”¼
- âœ… ìµœëŒ€ **5ë¶„ ì‘ì—… ì§€ì›** (ë¸Œë¼ìš°ì € ì œí•œ)
- âœ… **ì¶”ê°€ ì¸í”„ë¼ ë¶ˆí•„ìš”** (Redis, Docker ë“±)
- âœ… **ì‚¬ìš©ì ì§„ì…ì¥ë²½ 0** (Extension ì„¤ì¹˜ë§Œìœ¼ë¡œ ë™ì‘)
- âœ… **ë¦¬ì†ŒìŠ¤ ì†Œë¹„ ìµœì†Œ** (RAM 200MB ì´í•˜)

**ì‹¤ì œ ì‚¬ìš© íŒ¨í„´ ë¶„ì„ (ì˜ˆìƒ):**
```
ì‘ì—… ì‹œê°„ ë¶„í¬:
- 0-30ì´ˆ: 85% (ì¼ë°˜ ì±„íŒ…, ê°„ë‹¨í•œ ë„êµ¬ í˜¸ì¶œ)
- 30ì´ˆ-2ë¶„: 10% (ë³µì¡í•œ ì½”ë“œ ë¶„ì„, ë¬¸ì„œ ìš”ì•½)
- 2-5ë¶„: 4% (ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬)
- 5ë¶„ ì´ìƒ: 1% (ê·¹íˆ ë“œë¬¸ ì¼€ì´ìŠ¤)

â†’ 99%ì˜ ì‘ì—…ì´ Offscreen Documentë¡œ ì²˜ë¦¬ ê°€ëŠ¥
```

**5ë¶„ ì´ˆê³¼ ì‘ì—… ë°œìƒ ì‹œ ì ì§„ì  ëŒ€ì‘ (Event-Driven ë„ì… ì „):**

1. **Phase 4: ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘**
   - ì‘ì—… ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
   - 5ë¶„ ì´ˆê³¼ ì‘ì—… ë¹„ìœ¨ ì¸¡ì •

2. **Phase 5: Lightweight Job Queue**
   - SQLite ê¸°ë°˜ Job í…Œì´ë¸” (Redis ë¶ˆí•„ìš”)
   - FastAPI Background Tasks í™œìš©
   - Job ID ë°˜í™˜ í›„ í´ë§ (`GET /api/jobs/{id}/status`)
   - ì™„ë£Œ ì‹œ Browser Notification

3. **Phase 6: Full Event-Driven (ì¡°ê±´ë¶€)**
   - **ì¡°ê±´ 1**: 5ë¶„ ì´ìƒ ì‘ì—…ì´ 20% ì´ˆê³¼
   - **ì¡°ê±´ 2**: í´ë¼ìš°ë“œ ë°°í¬ ê²°ì • (ì‚¬ìš©ì PC â†’ ì„œë²„)
   - **ì¡°ê±´ 3**: Multi-User ì§€ì› í•„ìš”ì„± í™•ì¸

**Lightweight Job Queue ì˜ˆì‹œ (Event-Drivenë³´ë‹¤ ë‹¨ìˆœ):**
```python
# SQLiteë§Œìœ¼ë¡œ êµ¬í˜„ (Redis ë¶ˆí•„ìš”)
@router.post("/api/chat/async")
async def chat_async(body: ChatRequest, background_tasks: BackgroundTasks):
    job_id = str(uuid.uuid4())

    # FastAPI Background Task (ë³„ë„ Worker í”„ë¡œì„¸ìŠ¤ ë¶ˆí•„ìš”)
    background_tasks.add_task(execute_chat_task, job_id, body.message)

    return {"job_id": job_id, "status": "queued"}

# SQLiteì— Job ìƒíƒœ ì €ì¥
async def execute_chat_task(job_id: str, message: str):
    await job_storage.update(job_id, status="running")
    try:
        result = await orchestrator.process_message(message)
        await job_storage.update(job_id, status="completed", result=result)
    except Exception as e:
        await job_storage.update(job_id, status="failed", error=str(e))
```

**ê²°ë¡ :**
- í˜„ì¬ ë‹¨ê³„: **Offscreen Documentë¡œ ì¶©ë¶„**
- ë¬¸ì œ ë°œìƒ ì‹œ: **Lightweight Job Queue** (Redis ì—†ì´)
- ìµœí›„ ìˆ˜ë‹¨: **Full Event-Driven** (í´ë¼ìš°ë“œ ë°°í¬ ì‹œ)

---

## DoD (Definition of Done)

### Part E ì „ì²´

- [ ] MCP Gateway êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸ (Circuit Breaker, Rate Limiting, Fallback)
- [ ] Cost Tracker êµ¬í˜„ ë° LiteLLM í†µí•©
- [ ] Semantic Tool Router êµ¬í˜„ ë° ì„ë² ë”© ì¸ë±ì‹±
- [ ] Chaos Engineering ì‹œë‚˜ë¦¬ì˜¤ 3ê°œ í†µê³¼ (MCP ë‹¤ìš´, LLM Rate Limit, Race Condition)
- [ ] Plugin System ì¸í„°í˜ì´ìŠ¤ ì •ì˜ (Mock êµ¬í˜„)
- [ ] Backend coverage >= 90% ìœ ì§€
- [ ] ë¬¸ì„œí™”: Plugin ì•„ì´ë””ì–´ ì •ë¦¬ (ë³¸ íŒŒì¼ Step 16ì— í¬í•¨ ì™„ë£Œ)
- [ ] ë¬¸ì„œí™”: Event-Driven ë³´ë¥˜ ì‚¬ìœ  ìƒì„¸ ë¶„ì„ (ë³¸ íŒŒì¼ì— í¬í•¨ ì™„ë£Œ)
- [ ] ë¬¸ì„œí™”: `docs/architecture/plugin-system.md` ìƒì„± (Phase 5 ê¸°íš ì‹œ ì‘ì„±)

### ê²€ì¦ ëª…ë ¹ì–´

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ + ì»¤ë²„ë¦¬ì§€
pytest tests/ --cov=src --cov-fail-under=90 -q --tb=line -x

# Chaos Tests
pytest tests/chaos/ -v -m chaos

# Gateway í…ŒìŠ¤íŠ¸
pytest tests/unit/adapters/test_mcp_gateway.py -v

# Cost Tracker í…ŒìŠ¤íŠ¸
pytest tests/integration/adapters/test_cost_tracker.py -v
```

---

## ì°¸ê³  ìë£Œ

### Production Hardening
- [15 Best Practices for Production MCP Servers](https://thenewstack.io/15-best-practices-for-building-mcp-servers-in-production/)
- [What It Takes to Run MCP in Production](https://bytebridge.medium.com/what-it-takes-to-run-mcp-model-context-protocol-in-production-3bbf19413f69)
- [Circuit Breaker Pattern - Martin Fowler](https://martinfowler.com/bliki/CircuitBreaker.html)
- [Chaos Engineering Principles](https://principlesofchaos.org/)

### Observability & Cost Tracking
- [LiteLLM Callbacks](https://docs.litellm.ai/docs/observability/callbacks)
- [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings)

### Plugin System & Agent Frameworks
- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction)
- [AutoGen Documentation](https://microsoft.github.io/autogen/)
- [CrewAI Documentation](https://docs.crewai.com/)
- [Plugin Architecture Best Practices](https://www.oreilly.com/library/view/software-architecture-patterns/9781491971437/ch05.html)

### Event-Driven Architecture
- [Celery Documentation](https://docs.celeryq.dev/)
- [Redis Documentation](https://redis.io/docs/)
- [FastAPI Background Tasks](https://fastapi.tiangolo.com/tutorial/background-tasks/)

---

*ì‘ì„±ì¼: 2026-01-31*
*ìƒíƒœ: ì´ˆì•ˆ (Idea Stage)*
